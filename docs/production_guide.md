# Guia de Produ√ß√£o - UFRJ Storm

Este documento descreve como executar o pipeline completo de Machine Learning em ambiente de produ√ß√£o, fora do ambiente de notebook.

## üéØ Objetivo

Executar todo o pipeline de ML de forma automatizada, gerando:
- Modelos treinados e otimizados
- Predi√ß√µes com intervalos de confian√ßa
- Visualiza√ß√µes da s√©rie temporal completa
- Relat√≥rios de performance detalhados

## üìã Pr√©-requisitos Produtivos

### Ambiente T√©cnico
- Python 3.8+
- Mem√≥ria RAM: m√≠nimo 8GB (recomendado 16GB)
- Espa√ßo em disco: 2GB livres
- CPU: multi-core recomendado para treinamento

### Depend√™ncias
```bash
pip install -r requirements.txt
```

### Dados de Entrada
- Arquivo CSV com estrutura id√™ntica ao `tma_sp.csv`
- M√≠nimo 1000 registros para treinamento
- Features meteorol√≥gicas completas

## üîÑ Pipeline Produtivo

### Fase 1: Valida√ß√£o e Carregamento

```python
# 1.1 Executar testes de qualidade
from notebooks.data_quality_tests import run_data_quality_tests
test_results = run_data_quality_tests()

# Crit√©rio de parada: 100% dos testes aprovados
assert test_results['success_rate'] == 1.0, "Falha nos testes de qualidade"
```

**Crit√©rios de Aprova√ß√£o:**
- ‚úÖ 100% dos testes automatizados aprovados
- ‚úÖ Missing values < 5% por coluna
- ‚úÖ Consist√™ncia temporal > 90%
- ‚úÖ Vari√°veis target sem valores inv√°lidos

### Fase 2: Pr√©-processamento

```python
# 2.1 Aplicar limpeza dos dados
preprocessor = DataPreprocessor(config)
df_processed = preprocessor.prepare_features(df_raw)

# 2.2 Gerar features temporais
feature_cols = preprocessor.get_feature_columns(df_processed)

# 2.3 Dividir dados temporalmente
train_data, test_data = split_data_temporal(df_processed, config)

# 2.4 Escalonar features
X_train_scaled, X_test_scaled, scaler = preprocessor.scale_features(
    train_data[feature_cols], 
    test_data[feature_cols]
)
```

**Valida√ß√µes da Fase 2:**
- N√∫mero de features: 40 (esperado)
- Shape treino: (>=1000, 40)
- Shape teste: (>=200, 40)
- Escalamento aplicado com sucesso

### Fase 3: Treinamento dos Modelos

```python
# 3.1 Treinar modelo principal
lightning_predictor = LightningPredictor(config)
lightning_predictor.train_multiple_models(X_train_scaled, y_train)

# 3.2 Validar performance m√≠nima
best_model_rmse = lightning_predictor.model_scores[lightning_predictor.best_model_name]['rmse_cv_mean']
assert best_model_rmse < 3000, f"RMSE muito alto: {best_model_rmse}"

# 3.3 Treinar modelo de incerteza
uncertainty_predictor = UncertaintyPredictor(lightning_predictor)
uncertainty_predictor.train_uncertainty_model(X_train_scaled, y_train)
```

**Crit√©rios de Performance:**
- RMSE do melhor modelo < 3000
- R¬≤ > 0.25
- Modelo de incerteza treinado sem erros

### Fase 4: Valida√ß√£o Final

```python
# 4.1 Avaliar no conjunto de teste
test_results = lightning_predictor.evaluate_all_models(X_test_scaled, y_test)
uncertainty_results = uncertainty_predictor.evaluate_uncertainty(X_test_scaled, y_test)

# 4.2 Validar m√©tricas finais
best_r2 = test_results[lightning_predictor.best_model_name]['metrics']['r2']
coverage = uncertainty_results['coverage']

assert best_r2 > 0.20, f"R¬≤ insuficiente: {best_r2}"
assert coverage > 0.50, f"Cobertura baixa: {coverage}"
```

**M√©tricas M√≠nimas para Produ√ß√£o:**
- R¬≤ > 0.20
- RMSE < 3500
- MAE < 2000
- Cobertura do IC > 50%

### Fase 5: Salvamento e Deploy

```python
# 5.1 Salvar modelos treinados
lightning_predictor.save_model()
joblib.dump(uncertainty_predictor, '../models/uncertainty_model.joblib')
joblib.dump(scaler, '../models/scaler.joblib')

# 5.2 Salvar metadados
metadata = {
    'training_date': datetime.now().isoformat(),
    'model_performance': test_results[lightning_predictor.best_model_name]['metrics'],
    'uncertainty_coverage': uncertainty_results['coverage'],
    'feature_columns': feature_cols,
    'data_stats': {
        'train_samples': len(X_train_scaled),
        'test_samples': len(X_test_scaled),
        'features': len(feature_cols)
    }
}
with open('../models/metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)
```

## üöÄ Execu√ß√£o em Produ√ß√£o

### Script Principal

```python
def run_production_pipeline(input_file):
    """Executar pipeline completo de produ√ß√£o"""
    
    print("üöÄ INICIANDO PIPELINE PRODUTIVO UFRJ STORM")
    print("=" * 60)
    
    try:
        # Fase 1: Valida√ß√£o
        print("üìä Fase 1: Valida√ß√£o dos dados...")
        df = load_and_validate_data(input_file)
        
        # Fase 2: Pr√©-processamento
        print("üîß Fase 2: Pr√©-processamento...")
        X_train, X_test, y_train, y_test = preprocess_data(df)
        
        # Fase 3: Treinamento
        print("ü§ñ Fase 3: Treinamento dos modelos...")
        model1, model2 = train_models(X_train, y_train)
        
        # Fase 4: Valida√ß√£o
        print("üìà Fase 4: Valida√ß√£o final...")
        metrics = validate_models(model1, model2, X_test, y_test)
        
        # Fase 5: Deploy
        print("üíæ Fase 5: Salvamento dos modelos...")
        save_models(model1, model2, metrics)
        
        print("‚úÖ PIPELINE EXECUTADO COM SUCESSO!")
        return True
        
    except Exception as e:
        print(f"‚ùå ERRO NO PIPELINE: {str(e)}")
        return False

# Executar
success = run_production_pipeline('data/tma_sp.csv')
```

### Uso dos Modelos Treinados

```python
def predict_lightning(input_features):
    """Fazer predi√ß√µes com modelos treinados"""
    
    # Carregar modelos
    lightning_predictor = LightningPredictor.load_model('../models/model_random_forest.joblib')
    uncertainty_predictor = joblib.load('../models/uncertainty_model.joblib')
    scaler = joblib.load('../models/scaler.joblib')
    
    # Pr√©-processar entrada
    features_scaled = scaler.transform(input_features)
    
    # Predi√ß√µes
    base_prediction = lightning_predictor.best_model.predict(features_scaled)
    uncertainty_result = uncertainty_predictor.predict_with_uncertainty(features_scaled)
    
    return {
        'prediction': base_prediction[0],
        'confidence_interval': {
            'lower': uncertainty_result['lower_bound'][0],
            'upper': uncertainty_result['upper_bound'][0]
        },
        'uncertainty': uncertainty_result['uncertainty'][0]
    }
```

## üìä Monitoramento Produtivo

### M√©tricas a Acompanhar

1. **Performance do Modelo**
   - RMSE mensal
   - R¬≤ mensal  
   - Drift das features
   - Cobertura do IC

2. **Qualidade dos Dados**
   - Taxa de valores ausentes
   - Outliers detectados
   - Gaps temporais
   - Consist√™ncia das vari√°veis

3. **Sistema**
   - Tempo de execu√ß√£o
   - Uso de mem√≥ria
   - Taxa de erro
   - Disponibilidade

### Alertas Cr√≠ticos

```python
# Configurar alertas
ALERT_THRESHOLDS = {
    'rmse_max': 4000,
    'r2_min': 0.15,
    'coverage_min': 0.40,
    'missing_rate_max': 0.10,
    'execution_time_max': 3600  # 1 hora
}

def check_alerts(metrics):
    """Verificar se m√©tricas est√£o dentro dos limites"""
    alerts = []
    
    if metrics['rmse'] > ALERT_THRESHOLDS['rmse_max']:
        alerts.append(f"RMSE alto: {metrics['rmse']}")
    
    if metrics['r2'] < ALERT_THRESHOLDS['r2_min']:
        alerts.append(f"R¬≤ baixo: {metrics['r2']}")
    
    # ... outras verifica√ß√µes
    
    return alerts
```

## üîÑ Manuten√ß√£o e Retreinamento

### Crit√©rios para Retreinamento

- **Drift de Performance**: R¬≤ cai abaixo de 0.20 por 2 semanas consecutivas
- **Drift de Dados**: >30% das features com distribui√ß√£o significativamente diferente
- **Novos Dados**: Ac√∫mulo de >1000 novos registros validados
- **Periodicidade**: Retreinamento trimestral obrigat√≥rio

### Processo de Retreinamento

```python
def retrain_models():
    """Processo de retreinamento dos modelos"""
    
    # 1. Carregar novos dados
    new_data = load_new_data()
    
    # 2. Validar qualidade
    if not validate_new_data(new_data):
        raise ValueError("Dados novos n√£o passaram na valida√ß√£o")
    
    # 3. Retreinar modelos
    new_models = train_models(new_data)
    
    # 4. Validar performance
    if new_models['performance'] > current_models['performance']:
        # Deploy novos modelos
        deploy_models(new_models)
        # Backup modelos antigos
        backup_models(current_models)
    else:
        print("Novos modelos n√£o superam os atuais")
```

## üö® Troubleshooting Produtivo

### Problemas Comuns

#### 1. Falha no Carregamento dos Dados
```python
# Diagn√≥stico
- Verificar exist√™ncia do arquivo
- Validar formato CSV
- Checar encoding
- Verificar permiss√µes
```

#### 2. Erro no Pr√©-processamento
```python
# Solu√ß√µes
- Verificar nomes das colunas
- Validar tipos de dados
- Checar valores extremos
- Revisar features engineered
```

#### 3. Performance Degradada
```python
# Investiga√ß√£o
- Comparar distribui√ß√µes das features
- Analisar drift temporal
- Verificar outliers novos
- Avaliar missing patterns
```

#### 4. Erro na Predi√ß√£o
```python
# Debug
- Validar formato da entrada
- Verificar escalamento
- Checar dimens√µes dos arrays
- Confirmar modelos carregados
```

## üìà Otimiza√ß√µes Futuras

### Curto Prazo (1-3 meses)
- [ ] Otimiza√ß√£o de hiperpar√¢metros automatizada
- [ ] Pipeline de valida√ß√£o cruzada temporal
- [ ] Monitoramento autom√°tico de drift
- [ ] API REST para predi√ß√µes

### M√©dio Prazo (3-6 meses)
- [ ] Ensemble de modelos
- [ ] Feature selection autom√°tica
- [ ] Calibra√ß√£o avan√ßada da incerteza
- [ ] Dashboard de monitoramento

### Longo Prazo (6+ meses)
- [ ] Modelos deep learning
- [ ] Predi√ß√£o multi-step
- [ ] Incorpora√ß√£o de dados satelitais
- [ ] Sistema de alertas geogr√°ficos

---

**Mantenha este documento atualizado** conforme evolu√ß√µes no sistema produtivo.