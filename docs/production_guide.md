# Guia de Produ√ß√£o - UFRJ Storm

Este documento descreve como executar os pipelines de Machine Learning automatizados em ambiente de produ√ß√£o.

## üéØ Objetivo

Executar pipelines ML completamente automatizados usando as classes `LightningPredictor` e `UncertaintyPredictor` da biblioteca `src/models.py`, gerando:
- Modelos treinados e otimizados
- Predi√ß√µes com intervalos de confian√ßa 95%
- 5 visualiza√ß√µes autom√°ticas da s√©rie temporal
- Relat√≥rios JSON/texto detalhados

## ‚ö° Pipelines Dispon√≠veis

### Pipeline R√°pido (`run_quick_pipeline.py`)
- **Uso**: Demonstra√ß√£o e valida√ß√£o r√°pida
- **Algoritmo**: Random Forest otimizado
- **Tempo**: 2-3 minutos
- **Sa√≠da**: 5 plots + relat√≥rio JSON

### Pipeline de Produ√ß√£o (`run_production_pipeline.py`) 
- **Uso**: Ambiente produtivo completo
- **Algoritmos**: Todos os 7 algoritmos dispon√≠veis
- **Tempo**: 10-15 minutos  
- **Sa√≠da**: Sele√ß√£o autom√°tica do melhor modelo + todos os plots

## üìã Pr√©-requisitos Produtivos

### Ambiente T√©cnico
- Python 3.8+
- Mem√≥ria RAM: m√≠nimo 8GB (recomendado 16GB)
- Espa√ßo em disco: 2GB livres
- CPU: multi-core recomendado para treinamento

### Depend√™ncias
```bash
pip install -r requirements.txt
```

### Dados de Entrada
- Arquivo CSV com estrutura id√™ntica ao `tma_sp.csv`
- M√≠nimo 1000 registros para treinamento
- Features meteorol√≥gicas completas

## ÔøΩ Execu√ß√£o dos Pipelines

### Execu√ß√£o Simples

```bash
# Pipeline r√°pido (recomendado para valida√ß√£o)
python run_quick_pipeline.py

# Pipeline completo (produ√ß√£o)
python run_production_pipeline.py
```

### Sa√≠das Geradas

#### Visualiza√ß√µes (5 plots autom√°ticos):
1. **S√©rie temporal completa** (2000-2019)
2. **An√°lise detalhada** do per√≠odo de teste
3. **Acumulados mensais** com IC 95%
4. **Per√≠odo cont√≠nuo** de 30 dias
5. **Per√≠odo espec√≠fico** (Nov/2018 - Mar/2019)

#### Relat√≥rios:
- **JSON**: M√©tricas, features importantes, arquivos gerados
- **Modelo treinado**: Arquivo `.joblib` para uso posterior

## üîÑ Arquitetura do Pipeline

### Fase 1: Valida√ß√£o e Carregamento (Autom√°tica)

```python
# 1.1 A biblioteca src/models.py executa automaticamente:
# - Carregamento do CSV
# - Valida√ß√£o da estrutura dos dados
# - Testes de qualidade TDD (8 testes)
# - Pr√©-processamento e limpeza
```

**Crit√©rios de Aprova√ß√£o:**
- ‚úÖ 100% dos testes automatizados aprovados
- ‚úÖ Missing values < 5% por coluna
- ‚úÖ Consist√™ncia temporal > 90%
- ‚úÖ Vari√°veis target sem valores inv√°lidos

### Fase 2: Pr√©-processamento (Autom√°tico)

```python
# 2.1 A classe LightningPredictor executa automaticamente:
from src.models import LightningPredictor, UncertaintyPredictor

# Carregamento e pr√©-processamento integrados
lightning_predictor = LightningPredictor(config)
# Interno: limpeza, features temporais, escalamento, divis√£o temporal
```

**Valida√ß√µes da Fase 2:**
- N√∫mero de features: 40 (esperado)
- Shape treino: (>=1000, 40)
- Shape teste: (>=200, 40)
- Escalamento aplicado com sucesso

### Fase 3: Treinamento dos Modelos (Autom√°tico)

```python
# 3.1 Pipeline r√°pido
lightning_predictor.train_model()  # Random Forest otimizado

# 3.2 Pipeline produ√ß√£o  
lightning_predictor.train_multiple_models()  # 7 algoritmos + sele√ß√£o autom√°tica

# 3.3 Modelo de incerteza (ambos pipelines)
uncertainty_predictor = UncertaintyPredictor(lightning_predictor)
uncertainty_predictor.train_uncertainty_model()
```

**Crit√©rios de Performance:**
- RMSE do melhor modelo < 3000
- R¬≤ > 0.25
- Modelo de incerteza treinado sem erros

### Fase 4: Avalia√ß√£o e Visualiza√ß√£o (Autom√°tica)

```python
# 4.1 Avalia√ß√£o autom√°tica
# - M√©tricas de todos os modelos
# - Sele√ß√£o do melhor modelo
# - Intervalos de confian√ßa 95%

# 4.2 Gera√ß√£o autom√°tica de 5 plots:
# - S√©rie temporal completa
# - An√°lise detalhada do teste  
# - Acumulados mensais
# - Per√≠odo de 30 dias cont√≠nuos
# - Per√≠odo espec√≠fico Nov/2018-Mar/2019

# 4.3 Relat√≥rios autom√°ticos
# - JSON com m√©tricas e metadados
# - Salvamento do modelo treinado
```

**M√©tricas M√≠nimas para Produ√ß√£o:**
- R¬≤ > 0.20
- RMSE < 3500
- MAE < 2000
- Cobertura do IC > 50%

### Fase 5: Salvamento e Deploy

```python
# 5.1 Salvar modelos treinados
lightning_predictor.save_model()
joblib.dump(uncertainty_predictor, '../models/uncertainty_model.joblib')
joblib.dump(scaler, '../models/scaler.joblib')

# 5.2 Salvar metadados
metadata = {
    'training_date': datetime.now().isoformat(),
    'model_performance': test_results[lightning_predictor.best_model_name]['metrics'],
    'uncertainty_coverage': uncertainty_results['coverage'],
    'feature_columns': feature_cols,
    'data_stats': {
        'train_samples': len(X_train_scaled),
        'test_samples': len(X_test_scaled),
        'features': len(feature_cols)
    }
}
with open('../models/metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)
```

## üöÄ Execu√ß√£o em Produ√ß√£o

### Execu√ß√£o Direta dos Pipelines

```bash
# Pipeline r√°pido: demonstra√ß√£o com Random Forest
python run_quick_pipeline.py

# Sa√≠da esperada:
# üöÄ PIPELINE R√ÅPIDO UFRJ STORM - DEMONSTRA√á√ÉO
# ‚úÖ Dados carregados: 5857 registros, 33 colunas
# ‚úÖ Modelo Random Forest treinado
# ‚úÖ 5 plots gerados em /results/
# üéâ PIPELINE CONCLU√çDO COM SUCESSO!
```

```bash
# Pipeline de produ√ß√£o: todos os algoritmos
python run_production_pipeline.py

# Sa√≠da esperada:
# üöÄ PIPELINE PRODUTIVO UFRJ STORM
# ‚úÖ Dados processados e divididos
# ü§ñ Treinando 7 algoritmos ML...
# üèÜ Melhor modelo: random_forest (RMSE: 2888.85)
# üìà 5 visualiza√ß√µes geradas
# üíæ Modelo e relat√≥rios salvos
# üéâ PIPELINE CONCLU√çDO COM SUCESSO!
```

### Uso dos Modelos Treinados

```python
def predict_lightning(input_features):
    """Fazer predi√ß√µes com modelos treinados"""
    
    # Carregar modelos
    lightning_predictor = LightningPredictor.load_model('../models/model_random_forest.joblib')
    uncertainty_predictor = joblib.load('../models/uncertainty_model.joblib')
    scaler = joblib.load('../models/scaler.joblib')
    
    # Pr√©-processar entrada
    features_scaled = scaler.transform(input_features)
    
    # Predi√ß√µes
    base_prediction = lightning_predictor.best_model.predict(features_scaled)
    uncertainty_result = uncertainty_predictor.predict_with_uncertainty(features_scaled)
    
    return {
        'prediction': base_prediction[0],
        'confidence_interval': {
            'lower': uncertainty_result['lower_bound'][0],
            'upper': uncertainty_result['upper_bound'][0]
        },
        'uncertainty': uncertainty_result['uncertainty'][0]
    }
```

## üìä Monitoramento Produtivo

### M√©tricas a Acompanhar

1. **Performance do Modelo**
   - RMSE mensal
   - R¬≤ mensal  
   - Drift das features
   - Cobertura do IC

2. **Qualidade dos Dados**
   - Taxa de valores ausentes
   - Outliers detectados
   - Gaps temporais
   - Consist√™ncia das vari√°veis

3. **Sistema**
   - Tempo de execu√ß√£o
   - Uso de mem√≥ria
   - Taxa de erro
   - Disponibilidade

### Alertas Cr√≠ticos

```python
# Configurar alertas
ALERT_THRESHOLDS = {
    'rmse_max': 4000,
    'r2_min': 0.15,
    'coverage_min': 0.40,
    'missing_rate_max': 0.10,
    'execution_time_max': 3600  # 1 hora
}

def check_alerts(metrics):
    """Verificar se m√©tricas est√£o dentro dos limites"""
    alerts = []
    
    if metrics['rmse'] > ALERT_THRESHOLDS['rmse_max']:
        alerts.append(f"RMSE alto: {metrics['rmse']}")
    
    if metrics['r2'] < ALERT_THRESHOLDS['r2_min']:
        alerts.append(f"R¬≤ baixo: {metrics['r2']}")
    
    # ... outras verifica√ß√µes
    
    return alerts
```

## üîÑ Manuten√ß√£o e Retreinamento

### Crit√©rios para Retreinamento

- **Drift de Performance**: R¬≤ cai abaixo de 0.20 por 2 semanas consecutivas
- **Drift de Dados**: >30% das features com distribui√ß√£o significativamente diferente
- **Novos Dados**: Ac√∫mulo de >1000 novos registros validados
- **Periodicidade**: Retreinamento trimestral obrigat√≥rio

### Processo de Retreinamento

```python
def retrain_models():
    """Processo de retreinamento dos modelos"""
    
    # 1. Carregar novos dados
    new_data = load_new_data()
    
    # 2. Validar qualidade
    if not validate_new_data(new_data):
        raise ValueError("Dados novos n√£o passaram na valida√ß√£o")
    
    # 3. Retreinar modelos
    new_models = train_models(new_data)
    
    # 4. Validar performance
    if new_models['performance'] > current_models['performance']:
        # Deploy novos modelos
        deploy_models(new_models)
        # Backup modelos antigos
        backup_models(current_models)
    else:
        print("Novos modelos n√£o superam os atuais")
```

## üö® Troubleshooting Produtivo

### Problemas Comuns

#### 1. Falha no Carregamento dos Dados
```python
# Diagn√≥stico
- Verificar exist√™ncia do arquivo
- Validar formato CSV
- Checar encoding
- Verificar permiss√µes
```

#### 2. Erro no Pr√©-processamento
```python
# Solu√ß√µes
- Verificar nomes das colunas
- Validar tipos de dados
- Checar valores extremos
- Revisar features engineered
```

#### 3. Performance Degradada
```python
# Investiga√ß√£o
- Comparar distribui√ß√µes das features
- Analisar drift temporal
- Verificar outliers novos
- Avaliar missing patterns
```

#### 4. Erro na Predi√ß√£o
```python
# Debug
- Validar formato da entrada
- Verificar escalamento
- Checar dimens√µes dos arrays
- Confirmar modelos carregados
```

## üìà Otimiza√ß√µes Futuras

### Curto Prazo (1-3 meses)
- [ ] Otimiza√ß√£o de hiperpar√¢metros automatizada
- [ ] Pipeline de valida√ß√£o cruzada temporal
- [ ] Monitoramento autom√°tico de drift
- [ ] API REST para predi√ß√µes

### M√©dio Prazo (3-6 meses)
- [ ] Ensemble de modelos
- [ ] Feature selection autom√°tica
- [ ] Calibra√ß√£o avan√ßada da incerteza
- [ ] Dashboard de monitoramento

### Longo Prazo (6+ meses)
- [ ] Modelos deep learning
- [ ] Predi√ß√£o multi-step
- [ ] Incorpora√ß√£o de dados satelitais
- [ ] Sistema de alertas geogr√°ficos

---

**Mantenha este documento atualizado** conforme evolu√ß√µes no sistema produtivo.